<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>ESN Layers · ReservoirComputing.jl</title><meta name="title" content="ESN Layers · ReservoirComputing.jl"/><meta property="og:title" content="ESN Layers · ReservoirComputing.jl"/><meta property="twitter:title" content="ESN Layers · ReservoirComputing.jl"/><meta name="description" content="Documentation for ReservoirComputing.jl."/><meta property="og:description" content="Documentation for ReservoirComputing.jl."/><meta property="twitter:description" content="Documentation for ReservoirComputing.jl."/><meta property="og:url" content="https://docs.sciml.ai/ReservoirComputing/stable/api/esn_layers/"/><meta property="twitter:url" content="https://docs.sciml.ai/ReservoirComputing/stable/api/esn_layers/"/><link rel="canonical" href="https://docs.sciml.ai/ReservoirComputing/stable/api/esn_layers/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="ReservoirComputing.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">ReservoirComputing.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">ReservoirComputing.jl</a></li><li><span class="tocitem">General Settings</span><ul><li><a class="tocitem" href="../../general/different_training/">Changing Training Algorithms</a></li><li><a class="tocitem" href="../../general/states_variation/">Altering States</a></li><li><a class="tocitem" href="../../general/predictive_generative/">Generative vs Predictive</a></li></ul></li><li><span class="tocitem">Echo State Network Tutorials</span><ul><li><a class="tocitem" href="../../esn_tutorials/lorenz_basic/">Lorenz System Forecasting</a></li><li><a class="tocitem" href="../../esn_tutorials/change_layers/">Using Different Layers</a></li><li><a class="tocitem" href="../../esn_tutorials/different_drivers/">Using Different Reservoir Drivers</a></li><li><a class="tocitem" href="../../esn_tutorials/deep_esn/">Deep Echo State Networks</a></li><li><a class="tocitem" href="../../esn_tutorials/hybrid/">Hybrid Echo State Networks</a></li></ul></li><li><a class="tocitem" href="../../reca_tutorials/reca/">Reservoir Computing with Cellular Automata</a></li><li><span class="tocitem">API Documentation</span><ul><li><a class="tocitem" href="../training/">Training Algorithms</a></li><li><a class="tocitem" href="../states/">States Modifications</a></li><li><a class="tocitem" href="../predict/">Prediction Types</a></li><li><a class="tocitem" href="../esn/">Echo State Networks</a></li><li class="is-active"><a class="tocitem" href>ESN Layers</a><ul class="internal"><li><a class="tocitem" href="#Input-Layers"><span>Input Layers</span></a></li><li><a class="tocitem" href="#Reservoirs"><span>Reservoirs</span></a></li></ul></li><li><a class="tocitem" href="../esn_drivers/">ESN Drivers</a></li><li><a class="tocitem" href="../reca/">ReCA</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API Documentation</a></li><li class="is-active"><a href>ESN Layers</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>ESN Layers</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/ReservoirComputing.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/ReservoirComputing.jl/blob/master/docs/src/api/esn_layers.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="ESN-Layers"><a class="docs-heading-anchor" href="#ESN-Layers">ESN Layers</a><a id="ESN-Layers-1"></a><a class="docs-heading-anchor-permalink" href="#ESN-Layers" title="Permalink"></a></h1><h2 id="Input-Layers"><a class="docs-heading-anchor" href="#Input-Layers">Input Layers</a><a id="Input-Layers-1"></a><a class="docs-heading-anchor-permalink" href="#Input-Layers" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.WeightedLayer" href="#ReservoirComputing.WeightedLayer"><code>ReservoirComputing.WeightedLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WeightedInput(scaling)
WeightedInput(;scaling=0.1)</code></pre><p>Creates a <code>WeightedInput</code> layer initializer for Echo State Networks. This initializer generates a weighted input matrix with random non-zero elements distributed uniformly within the range [-<code>scaling</code>, <code>scaling</code>], following the approach in <sup class="footnote-reference"><a id="citeref-Lu" href="#footnote-Lu">[Lu]</a></sup>.</p><p><strong>Parameters</strong></p><ul><li><code>scaling</code>: The scaling factor for the weight distribution (default: 0.1).</li></ul><p><strong>Returns</strong></p><ul><li>A <code>WeightedInput</code> instance to be used for initializing the input layer of an ESN.</li></ul><p>Reference: <sup class="footnote-reference"><a id="citeref-Lu" href="#footnote-Lu">[Lu]</a></sup>: Lu, Zhixin, et al.     &quot;Reservoir observers: Model-free inference of unmeasured variables in chaotic systems.&quot;     Chaos: An Interdisciplinary Journal of Nonlinear Science 27.4 (2017): 041102.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_input_layers.jl#L7-L26">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.DenseLayer" href="#ReservoirComputing.DenseLayer"><code>ReservoirComputing.DenseLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DenseLayer(scaling)
DenseLayer(;scaling=0.1)</code></pre><p>Creates a <code>DenseLayer</code> initializer for Echo State Networks, generating a fully connected input layer. The layer is initialized with random weights uniformly distributed within [-<code>scaling</code>, <code>scaling</code>]. This scaling factor can be provided either as an argument or a keyword argument. The <code>DenseLayer</code> is the default input layer in <code>ESN</code> construction.</p><p><strong>Parameters</strong></p><ul><li><code>scaling</code>: The scaling factor for weight distribution (default: 0.1).</li></ul><p><strong>Returns</strong></p><ul><li>A <code>DenseLayer</code> instance for initializing the ESN&#39;s input layer.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_input_layers.jl#L52-L66">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.SparseLayer" href="#ReservoirComputing.SparseLayer"><code>ReservoirComputing.SparseLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SparseLayer(scaling, sparsity)
SparseLayer(scaling; sparsity=0.1)
SparseLayer(;scaling=0.1, sparsity=0.1)</code></pre><p>Creates a <code>SparseLayer</code> initializer for Echo State Networks, generating a sparse input layer. The layer is initialized with weights distributed within [-<code>scaling</code>, <code>scaling</code>] and a specified <code>sparsity</code> level. Both <code>scaling</code> and <code>sparsity</code> can be set as arguments or keyword arguments.</p><p><strong>Parameters</strong></p><ul><li><code>scaling</code>: Scaling factor for weight distribution (default: 0.1).</li><li><code>sparsity</code>: Sparsity level of the layer (default: 0.1).</li></ul><p><strong>Returns</strong></p><ul><li>A <code>SparseLayer</code> instance for initializing ESN&#39;s input layer with sparse connections.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_input_layers.jl#L97-L112">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.InformedLayer" href="#ReservoirComputing.InformedLayer"><code>ReservoirComputing.InformedLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">InformedLayer(model_in_size; scaling=0.1, gamma=0.5)</code></pre><p>Creates an <code>InformedLayer</code> initializer for Echo State Networks (ESNs) that generates a weighted input layer matrix. The matrix contains random non-zero elements drawn from the range [-<code>scaling</code>, <code>scaling</code>]. This initializer ensures that a fraction (<code>gamma</code>) of reservoir nodes are exclusively connected to the raw inputs, while the rest are connected to the outputs of a prior knowledge model, as described in <sup class="footnote-reference"><a id="citeref-Pathak" href="#footnote-Pathak">[Pathak]</a></sup>.</p><p><strong>Arguments</strong></p><ul><li><code>model_in_size</code>: The size of the prior knowledge model&#39;s output,   which determines the number of columns in the input layer matrix.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>scaling</code>: The absolute value of the weights (default: 0.1).</li><li><code>gamma</code>: The fraction of reservoir nodes connected exclusively to raw inputs (default: 0.5).</li></ul><p><strong>Returns</strong></p><ul><li>An <code>InformedLayer</code> instance for initializing the ESN&#39;s input layer matrix.</li></ul><p>Reference: <sup class="footnote-reference"><a id="citeref-Pathak" href="#footnote-Pathak">[Pathak]</a></sup>: Jaideep Pathak et al.      &quot;Hybrid Forecasting of Chaotic Processes: Using Machine Learning in Conjunction with a Knowledge-Based Model&quot; (2018).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_input_layers.jl#L289-L312">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.MinimumLayer" href="#ReservoirComputing.MinimumLayer"><code>ReservoirComputing.MinimumLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MinimumLayer(weight, sampling)
MinimumLayer(weight; sampling=BernoulliSample(0.5))
MinimumLayer(;weight=0.1, sampling=BernoulliSample(0.5))</code></pre><p>Creates a <code>MinimumLayer</code> initializer for Echo State Networks, generating a fully connected input layer. This layer has a uniform absolute weight value (<code>weight</code>) with the sign of each weight determined by the <code>sampling</code> method. This approach, as detailed in <sup class="footnote-reference"><a id="citeref-Rodan1" href="#footnote-Rodan1">[Rodan1]</a></sup> and <sup class="footnote-reference"><a id="citeref-Rodan2" href="#footnote-Rodan2">[Rodan2]</a></sup>, allows for controlled weight distribution in the layer.</p><p><strong>Parameters</strong></p><ul><li><code>weight</code>: Absolute value of weights in the layer.</li><li><code>sampling</code>: Method for determining the sign of weights (default: <code>BernoulliSample(0.5)</code>).</li></ul><p><strong>Returns</strong></p><ul><li>A <code>MinimumLayer</code> instance for initializing the ESN&#39;s input layer.</li></ul><p>References: <sup class="footnote-reference"><a id="citeref-Rodan1" href="#footnote-Rodan1">[Rodan1]</a></sup>: Rodan, Ali, and Peter Tino.     &quot;Minimum complexity echo state network.&quot;     IEEE Transactions on Neural Networks 22.1 (2010): 131-144. <sup class="footnote-reference"><a id="citeref-Rodan2" href="#footnote-Rodan2">[Rodan2]</a></sup>: Rodan, Ali, and Peter Tiňo.     &quot;Simple deterministically constructed cycle reservoirs with regular jumps.&quot;     Neural Computation 24.7 (2012): 1822-1852.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_input_layers.jl#L203-L227">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.NullLayer" href="#ReservoirComputing.NullLayer"><code>ReservoirComputing.NullLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NullLayer()</code></pre><p>Creates a <code>NullLayer</code> initializer for Echo State Networks (ESNs) that generates a vector of zeros.</p><p><strong>Returns</strong></p><ul><li>A <code>NullLayer</code> instance for initializing the ESN&#39;s input layer matrix.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_input_layers.jl#L356-L363">source</a></section></article><p>The signs in the <code>MinimumLayer</code> are chosen based on the following methods:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.BernoulliSample" href="#ReservoirComputing.BernoulliSample"><code>ReservoirComputing.BernoulliSample</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">BernoulliSample(p)
BernoulliSample(;p=0.5)</code></pre><p>Creates a <code>BernoulliSample</code> constructor for the <code>MinimumLayer</code>. It uses a Bernoulli distribution to determine the sign of weights in the input layer. The parameter <code>p</code> sets the probability of a weight being positive, as per the <code>Distributions</code> package. This method of sign weight determination for input layers is based on the approach in <sup class="footnote-reference"><a id="citeref-Rodan" href="#footnote-Rodan">[Rodan]</a></sup>.</p><p><strong>Parameters</strong></p><ul><li><code>p</code>: Probability of a positive weight (default: 0.5).</li></ul><p><strong>Returns</strong></p><ul><li>A <code>BernoulliSample</code> instance for generating sign weights in <code>MinimumLayer</code>.</li></ul><p>Reference: <sup class="footnote-reference"><a id="citeref-Rodan" href="#footnote-Rodan">[Rodan]</a></sup>: Rodan, Ali, and Peter Tino.     &quot;Minimum complexity echo state network.&quot;      IEEE Transactions on Neural Networks 22.1 (2010): 131-144.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_input_layers.jl#L144-L163">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.IrrationalSample" href="#ReservoirComputing.IrrationalSample"><code>ReservoirComputing.IrrationalSample</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">IrrationalSample(irrational, start)
IrrationalSample(;irrational=pi, start=1)</code></pre><p>Creates an <code>IrrationalSample</code> constructor for the <code>MinimumLayer</code>. It determines the sign of weights in the input layer based on the decimal expansion of an <code>irrational</code> number. The <code>start</code> parameter sets the starting point in the decimal sequence. The signs are assigned based on the thresholding of each decimal digit against 4.5, as described in <sup class="footnote-reference"><a id="citeref-Rodan" href="#footnote-Rodan">[Rodan]</a></sup>.</p><p><strong>Parameters</strong></p><ul><li><code>irrational</code>: An irrational number for weight sign determination (default: π).</li><li><code>start</code>: Starting index in the decimal expansion (default: 1).</li></ul><p><strong>Returns</strong></p><ul><li>An <code>IrrationalSample</code> instance for generating sign weights in <code>MinimumLayer</code>.</li></ul><p>Reference: <sup class="footnote-reference"><a id="citeref-Rodan" href="#footnote-Rodan">[Rodan]</a></sup>: Rodan, Ali, and Peter Tiňo.     &quot;Simple deterministically constructed cycle reservoirs with regular jumps.&quot;     Neural Computation 24.7 (2012): 1822-1852.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_input_layers.jl#L173-L193">source</a></section></article><p>To derive the matrix one can call the following function:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.create_layer" href="#ReservoirComputing.create_layer"><code>ReservoirComputing.create_layer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">create_layer(input_layer::AbstractLayer, res_size, in_size)</code></pre><p>Generates a matrix layer of size <code>res_size</code> x <code>in_size</code>, constructed according to the specifications of the <code>input_layer</code>.</p><p><strong>Parameters</strong></p><ul><li><code>input_layer</code>: An instance of <code>AbstractLayer</code> determining the layer construction.</li><li><code>res_size</code>: The number of rows (reservoir size) for the layer.</li><li><code>in_size</code>: The number of columns (input size) for the layer.</li></ul><p><strong>Returns</strong></p><ul><li>A matrix representing the constructed layer.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_input_layers.jl#L75-L87">source</a></section></article><p>To create new input layers, it suffices to define a new struct containing the needed parameters of the new input layer. This struct will need to be an <code>AbstractLayer</code>, so the <code>create_layer</code> function can be dispatched over it. The workflow should follow this snippet:</p><pre><code class="language-julia hljs">#creation of the new struct for the layer
struct MyNewLayer &lt;: AbstractLayer
    #the layer params go here
end

#dispatch over the function to actually build the layer matrix
function create_layer(input_layer::MyNewLayer, res_size, in_size)
    #the new algorithm to build the input layer goes here
end</code></pre><h2 id="Reservoirs"><a class="docs-heading-anchor" href="#Reservoirs">Reservoirs</a><a id="Reservoirs-1"></a><a class="docs-heading-anchor-permalink" href="#Reservoirs" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.RandSparseReservoir" href="#ReservoirComputing.RandSparseReservoir"><code>ReservoirComputing.RandSparseReservoir</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RandSparseReservoir(res_size, radius, sparsity)
RandSparseReservoir(res_size; radius=1.0, sparsity=0.1)</code></pre><p>Returns a random sparse reservoir initializer, which generates a matrix of size <code>res_size x res_size</code> with the specified <code>sparsity</code> and scaled spectral radius according to <code>radius</code>. This type of reservoir initializer is commonly used in Echo State Networks (ESNs) for capturing complex temporal dependencies.</p><p><strong>Arguments</strong></p><ul><li><code>res_size</code>: The size of the reservoir matrix.</li><li><code>radius</code>: The desired spectral radius of the reservoir. By default, it is set to 1.0.</li><li><code>sparsity</code>: The sparsity level of the reservoir matrix, controlling the fraction of zero elements. By default, it is set to 0.1.</li></ul><p><strong>Returns</strong></p><p>A RandSparseReservoir object that can be used as a reservoir initializer in ESN construction.</p><p><strong>References</strong></p><p>This type of reservoir initialization is a common choice in ESN construction for its ability to capture temporal dependencies in data. However, there is no specific reference associated with this function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_reservoirs.jl#L17-L34">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.PseudoSVDReservoir" href="#ReservoirComputing.PseudoSVDReservoir"><code>ReservoirComputing.PseudoSVDReservoir</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PseudoSVDReservoir(max_value, sparsity, sorted, reverse_sort)
PseudoSVDReservoir(max_value, sparsity; sorted=true, reverse_sort=false)</code></pre><p>Returns an initializer to build a sparse reservoir matrix with the given <code>sparsity</code> by using a pseudo-SVD approach as described in <sup class="footnote-reference"><a id="citeref-yang" href="#footnote-yang">[yang]</a></sup>.</p><p><strong>Arguments</strong></p><ul><li><code>res_size</code>: The size of the reservoir matrix.</li><li><code>max_value</code>: The maximum absolute value of elements in the matrix.</li><li><code>sparsity</code>: The desired sparsity level of the reservoir matrix.</li><li><code>sorted</code>: A boolean indicating whether to sort the singular values before creating the diagonal matrix. By default, it is set to <code>true</code>.</li><li><code>reverse_sort</code>: A boolean indicating whether to reverse the sorted singular values. By default, it is set to <code>false</code>.</li></ul><p><strong>Returns</strong></p><p>A PseudoSVDReservoir object that can be used as a reservoir initializer in ESN construction.</p><p><strong>References</strong></p><p>This reservoir initialization method, based on a pseudo-SVD approach, is inspired by the work in <sup class="footnote-reference"><a id="citeref-yang" href="#footnote-yang">[yang]</a></sup>, which focuses on designing polynomial echo state networks for time series prediction.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_reservoirs.jl#L103-L123">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.DelayLineReservoir" href="#ReservoirComputing.DelayLineReservoir"><code>ReservoirComputing.DelayLineReservoir</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DelayLineReservoir(res_size, weight)
DelayLineReservoir(res_size; weight=0.1)</code></pre><p>Returns a Delay Line Reservoir matrix constructor to obtain a deterministic reservoir as described in <sup class="footnote-reference"><a id="citeref-Rodan2010" href="#footnote-Rodan2010">[Rodan2010]</a></sup>.</p><p><strong>Arguments</strong></p><ul><li><code>res_size::Int</code>: The size of the reservoir.</li><li><code>weight::T</code>: The weight determines the absolute value of all the connections in the reservoir.</li></ul><p><strong>Returns</strong></p><p>A <code>DelayLineReservoir</code> object.</p><p><strong>References</strong></p><p>IEEE transactions on neural networks 22.1 (2010): 131-144.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_reservoirs.jl#L194-L211">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.DelayLineBackwardReservoir" href="#ReservoirComputing.DelayLineBackwardReservoir"><code>ReservoirComputing.DelayLineBackwardReservoir</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DelayLineBackwardReservoir(res_size, weight, fb_weight)
DelayLineBackwardReservoir(res_size; weight=0.1, fb_weight=0.2)</code></pre><p>Returns a Delay Line Reservoir constructor to create a matrix with backward connections as described in <sup class="footnote-reference"><a id="citeref-Rodan2010" href="#footnote-Rodan2010">[Rodan2010]</a></sup>. The <code>weight</code> and <code>fb_weight</code> can be passed as either arguments or keyword arguments, and they determine the absolute values of the connections in the reservoir.</p><p><strong>Arguments</strong></p><ul><li><code>res_size::Int</code>: The size of the reservoir.</li><li><code>weight::T</code>: The weight determines the absolute value of forward connections in the reservoir.</li><li><code>fb_weight::T</code>: The <code>fb_weight</code> determines the absolute value of backward connections in the reservoir.</li></ul><p><strong>Returns</strong></p><p>A <code>DelayLineBackwardReservoir</code> object.</p><p><strong>References</strong></p><p>IEEE transactions on neural networks 22.1 (2010): 131-144.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_reservoirs.jl#L236-L255">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.SimpleCycleReservoir" href="#ReservoirComputing.SimpleCycleReservoir"><code>ReservoirComputing.SimpleCycleReservoir</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SimpleCycleReservoir(res_size, weight)
SimpleCycleReservoir(res_size; weight=0.1)</code></pre><p>Returns a Simple Cycle Reservoir constructor to build a reservoir matrix as described in <sup class="footnote-reference"><a id="citeref-Rodan2010" href="#footnote-Rodan2010">[Rodan2010]</a></sup>. The <code>weight</code> can be passed as an argument or a keyword argument, and it determines the absolute value of all the connections in the reservoir.</p><p><strong>Arguments</strong></p><ul><li><code>res_size::Int</code>: The size of the reservoir.</li><li><code>weight::T</code>: The weight determines the absolute value of connections in the reservoir.</li></ul><p><strong>Returns</strong></p><p>A <code>SimpleCycleReservoir</code> object.</p><p><strong>References</strong></p><p>IEEE transactions on neural networks 22.1 (2010): 131-144.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_reservoirs.jl#L280-L298">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.CycleJumpsReservoir" href="#ReservoirComputing.CycleJumpsReservoir"><code>ReservoirComputing.CycleJumpsReservoir</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CycleJumpsReservoir(res_size; cycle_weight=0.1, jump_weight=0.1, jump_size=3)
CycleJumpsReservoir(res_size, cycle_weight, jump_weight, jump_size)</code></pre><p>Return a Cycle Reservoir with Jumps constructor to create a reservoir matrix as described in <sup class="footnote-reference"><a id="citeref-Rodan2012" href="#footnote-Rodan2012">[Rodan2012]</a></sup>. The <code>cycle_weight</code>, <code>jump_weight</code>, and <code>jump_size</code> can be passed as arguments or keyword arguments, and they determine the absolute values of connections in the reservoir. The <code>jump_size</code> determines the jumps between <code>jump_weight</code>s.</p><p><strong>Arguments</strong></p><ul><li><code>res_size::Int</code>: The size of the reservoir.</li><li><code>cycle_weight::T</code>: The weight of cycle connections.</li><li><code>jump_weight::T</code>: The weight of jump connections.</li><li><code>jump_size::Int</code>: The number of steps between jump connections.</li></ul><p><strong>Returns</strong></p><p>A <code>CycleJumpsReservoir</code> object.</p><p><strong>References</strong></p><p>with regular jumps.&quot; Neural computation 24.7 (2012): 1822-1852.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_reservoirs.jl#L325-L345">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.NullReservoir" href="#ReservoirComputing.NullReservoir"><code>ReservoirComputing.NullReservoir</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NullReservoir()</code></pre><p>Return a constructor for a matrix of zeros with dimensions <code>res_size x res_size</code>.</p><p><strong>Arguments</strong></p><ul><li>None</li></ul><p><strong>Returns</strong></p><p>A <code>NullReservoir</code> object.</p><p><strong>References</strong></p><ul><li>None</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_reservoirs.jl#L373-L386">source</a></section></article><p>Like for the input layers, to actually build the matrix of the reservoir, one can call the following function:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ReservoirComputing.create_reservoir" href="#ReservoirComputing.create_reservoir"><code>ReservoirComputing.create_reservoir</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">create_reservoir(reservoir::AbstractReservoir, res_size)
create_reservoir(reservoir, args...)</code></pre><p>Given an <code>AbstractReservoir</code> constructor and the size of the reservoir (<code>res_size</code>), this function returns the corresponding reservoir matrix. Alternatively, it accepts a pre-generated matrix.</p><p><strong>Arguments</strong></p><ul><li><code>reservoir</code>: An <code>AbstractReservoir</code> object or constructor.</li><li><code>res_size</code>: The size of the reservoir matrix.</li><li><code>matrix_type</code>: The type of the resulting matrix. By default, it is set to <code>Matrix{Float64}</code>.</li></ul><p><strong>Returns</strong></p><p>A matrix representing the reservoir, generated based on the properties of the specified <code>reservoir</code> object or constructor.</p><p><strong>References</strong></p><p>The choice of reservoir initialization is crucial in Echo State Networks (ESNs) for achieving effective temporal modeling. Specific references for reservoir initialization methods may vary based on the type of reservoir used, but the practice of initializing reservoirs for ESNs is widely documented in the ESN literature.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/3766b6f9be40cbbf4695423b7c3c093e526f64eb/src/esn/esn_reservoirs.jl#L39-L55">source</a></section></article><p>To create a new reservoir, the procedure is similar to the one for the input layers. First, the definition of the new struct of type <code>AbstractReservoir</code> with the reservoir parameters is needed. Then the dispatch over the <code>create_reservoir</code> function makes the model actually build the reservoir matrix. An example of the workflow is given in the following snippet:</p><pre><code class="language-julia hljs">#creation of the new struct for the reservoir
struct MyNewReservoir &lt;: AbstractReservoir
    #the reservoir params go here
end

#dispatch over the function to build the reservoir matrix
function create_reservoir(reservoir::AbstractReservoir, res_size)
    #the new algorithm to build the reservoir matrix goes here
end</code></pre><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-yang"><a class="tag is-link" href="#citeref-yang">yang</a>Yang, Cuili, et al. &quot;<em>Design of polynomial echo state networks for time series prediction.</em>&quot; Neurocomputing 290 (2018): 148-160.</li><li class="footnote" id="footnote-Rodan2010"><a class="tag is-link" href="#citeref-Rodan2010">Rodan2010</a>Rodan, Ali, and Peter Tino. &quot;Minimum complexity echo state network.&quot;</li><li class="footnote" id="footnote-Rodan2010"><a class="tag is-link" href="#citeref-Rodan2010">Rodan2010</a>Rodan, Ali, and Peter Tino. &quot;Minimum complexity echo state network.&quot;</li><li class="footnote" id="footnote-Rodan2010"><a class="tag is-link" href="#citeref-Rodan2010">Rodan2010</a>Rodan, Ali, and Peter Tino. &quot;Minimum complexity echo state network.&quot;</li><li class="footnote" id="footnote-Rodan2012"><a class="tag is-link" href="#citeref-Rodan2012">Rodan2012</a>Rodan, Ali, and Peter Tiňo. &quot;Simple deterministically constructed cycle reservoirs</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../esn/">« Echo State Networks</a><a class="docs-footer-nextpage" href="../esn_drivers/">ESN Drivers »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Saturday 23 December 2023 15:08">Saturday 23 December 2023</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
